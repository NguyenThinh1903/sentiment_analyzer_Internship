# app.py (Ki·ªÉm tra l·∫°i th·ª•t d√≤ng cho c√°c kh·ªëi with)

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import os
import time
import requests
import json
import traceback
from collections import Counter

import config
# Import visualization ch·ªâ d√πng cho Tab 3
try:
    from visualization import plot_confusion_matrix, plot_training_history
    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False
    print("C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y module 'visualization'. Tab 3 s·∫Ω thi·∫øu m·ªôt s·ªë h√¨nh ·∫£nh.")


# --- C·∫•u h√¨nh Trang ---
st.set_page_config(page_title="X·ª≠ l√Ω Ph·∫£n h·ªìi (Lai gh√©p)", page_icon="üöÄ", layout="wide")

# --- ƒê·ªãa ch·ªâ API Backend ---
# ƒê·∫£m b·∫£o API Host v√† Port ƒë√∫ng trong config.py
BACKEND_API_URL = f"http://{getattr(config, 'API_HOST', '127.0.0.1')}:{getattr(config, 'API_PORT', 8000)}/process_comment_hybrid/"

# --- Giao di·ªán Ch√≠nh ---
st.title("üöÄ H·ªá th·ªëng X·ª≠ l√Ω Ph·∫£n h·ªìi Kh√°ch h√†ng (Lai gh√©p AI)")
st.markdown("Nh·∫≠p ph·∫£n h·ªìi ho·∫∑c t·∫£i file CSV. H·ªá th·ªëng s·∫Ω d√πng model local v√† g·ªçi AI (Gemini) khi c·∫ßn thi·∫øt.")

# --- C√°c Tab ch·ª©c nƒÉng ---
tab1, tab2, tab3 = st.tabs(["üìù X·ª≠ l√Ω ƒê∆°n l·∫ª", "üìÇ X·ª≠ l√Ω H√†ng lo·∫°t (CSV)", "üìà Th√¥ng tin Model XLM-R"])


# --- Tab 1: X·ª≠ l√Ω ƒê∆°n l·∫ª ---
# ƒê·∫£m b·∫£o kh·ªëi n√†y c√≥ n·ªôi dung th·ª•t v√†o
with tab1:
    st.header("Nh·∫≠p ph·∫£n h·ªìi c·∫ßn x·ª≠ l√Ω:")
    user_input = st.text_area("Nh·∫≠p vƒÉn b·∫£n...", height=150, key="single_hybrid", placeholder="V√≠ d·ª•: S·∫£n ph·∫©m t·ªët nh∆∞ng giao h√†ng h∆°i ch·∫≠m.")

    if st.button("üöÄ X·ª≠ l√Ω Ngay!", key="analyze_single_hybrid"):
        if user_input and user_input.strip():
            start_time = time.time()
            with st.spinner('üß† ƒêang x·ª≠ l√Ω...'):
                api_response = None; error_message = None
                try:
                    response = requests.post(BACKEND_API_URL, json={"comment": user_input}, timeout=120)
                    response.raise_for_status(); api_response = response.json()
                except requests.exceptions.RequestException as e: error_message = f"L·ªói k·∫øt n·ªëi API Backend ({BACKEND_API_URL}): {e}"
                except json.JSONDecodeError: error_message = f"L·ªói ƒë·ªçc JSON t·ª´ API. Status: {response.status_code}. Response: {response.text[:500]}"
                except Exception as e: error_message = f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"; traceback.print_exc()

            end_time = time.time()

            if error_message:
                st.error(error_message)
                st.info("M·∫πo: ƒê·∫£m b·∫£o server API Backend (uvicorn api:app --reload) ƒëang ch·∫°y v√† kh√¥ng c√≥ l·ªói.")
            elif api_response:
                st.subheader("K·∫øt qu·∫£ X·ª≠ l√Ω:")
                total_time = (end_time - start_time) * 1000
                api_time = api_response.get('processing_time_ms')
                ai_reason = api_response.get('ai_call_reason', 'N/A')

                col_res1, col_res2 = st.columns(2)
                with col_res1:
                    st.markdown("**Ph√¢n t√≠ch C·∫£m x√∫c (Model Local):**")
                    sentiment = api_response.get('sentiment', 'N/A')
                    confidence = api_response.get('confidence')
                    try: # T√¥ m√†u
                        label_map = getattr(config, 'TARGET_LABEL_MAP', {}) # L·∫•y map t·ª´ config an to√†n
                        positive_label = label_map.get(2, "T√≠ch c·ª±c")
                        negative_label = label_map.get(0, "Ti√™u c·ª±c")
                        if sentiment == positive_label: st.success(f"**C·∫£m x√∫c:** {sentiment}")
                        elif sentiment == negative_label: st.error(f"**C·∫£m x√∫c:** {sentiment}")
                        else: st.warning(f"**C·∫£m x√∫c:** {sentiment}")
                    except Exception: st.write(f"**C·∫£m x√∫c:** {sentiment}")

                    if confidence is not None: st.metric(label="ƒê·ªô tin c·∫≠y", value=f"{confidence:.2%}")
                    st.caption(f"T·ªïng T.gian: {total_time:.0f}ms | API T.gian: {api_time:.0f}ms" if api_time else f"T·ªïng T.gian: {total_time:.0f}ms")
                    st.caption(f"L√Ω do g·ªçi AI: {ai_reason}")

                with col_res2:
                    st.markdown("**G·ª£i √Ω Ph·∫£n h·ªìi T·ª± ƒë·ªông (AI):**")
                    generated_response = api_response.get('generated_response')
                    if generated_response and "L·ªói" not in generated_response and "ch∆∞a c·∫•u h√¨nh" not in generated_response:
                        st.text_area("N·ªôi dung:", value=generated_response, height=150, key="gen_resp_area_h", disabled=False, help="B·∫°n c√≥ th·ªÉ ch·ªânh s·ª≠a n·ªôi dung n√†y tr∆∞·ªõc khi s·ª≠ d·ª•ng.")
                    else:
                        st.info(generated_response or "Kh√¥ng c√≥ g·ª£i √Ω ph·∫£n h·ªìi.")

                st.markdown("---")
                st.markdown("**G·ª£i √Ω H√†nh ƒë·ªông N·ªôi b·ªô (AI):**")
                suggestions = api_response.get('suggestions')
                if suggestions and not any("L·ªói" in s or "ch∆∞a c·∫•u h√¨nh" in s for s in suggestions):
                    for i, suggestion in enumerate(suggestions): st.markdown(f"{i+1}. {suggestion}")
                else:
                    st.info(suggestions[0] if suggestions else "Kh√¥ng c√≥ g·ª£i √Ω h√†nh ƒë·ªông.")
            else:
                 st.error("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi h·ª£p l·ªá t·ª´ API.")
        else:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p vƒÉn b·∫£n.")


# --- Tab 2: X·ª≠ l√Ω H√†ng lo·∫°t (CSV) ---
# ƒê·∫£m b·∫£o kh·ªëi n√†y c√≥ n·ªôi dung th·ª•t v√†o
with tab2:
    st.header("T·∫£i l√™n file CSV ƒë·ªÉ x·ª≠ l√Ω h√†ng lo·∫°t (Lai gh√©p):")
    # L·∫•y t√™n c·ªôt an to√†n t·ª´ config
    text_col_name = getattr(config, 'TEXT_COLUMN', 'comment')
    uploaded_file = st.file_uploader(f"Ch·ªçn file CSV (c·ªôt '{text_col_name}')", type=["csv"], key="csv_hybrid", help=f"C·ªôt '{text_col_name}' s·∫Ω ƒë∆∞·ª£c x·ª≠ l√Ω.")

    col_limit1, col_limit2 = st.columns([1, 3])
    with col_limit1:
        limit_enabled = st.checkbox("Gi·ªõi h·∫°n s·ªë d√≤ng?", key="limit_checkbox", value=False)
    with col_limit2:
        limit_rows_hybrid = st.number_input(
            "S·ªë d√≤ng mu·ªën x·ª≠ l√Ω t√≠nh t·ª´ ƒë·∫ßu file:", min_value=1, value=50, step=10,
            key="limit_rows_input_conditional", disabled=not limit_enabled,
            help="Tick v√†o √¥ b√™n c·∫°nh ƒë·ªÉ b·∫≠t gi·ªõi h·∫°n."
        )

    if uploaded_file is not None:
        try:
            with st.spinner("ƒêang ƒë·ªçc CSV..."):
                try: df = pd.read_csv(uploaded_file, encoding='utf-8-sig', low_memory=False)
                except: df = pd.read_csv(uploaded_file, encoding='utf-8', low_memory=False)
            st.success(f"‚úÖ ƒê√£ t·∫£i file '{uploaded_file.name}' ({len(df)} d√≤ng).")
            if text_col_name not in df.columns:
                st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y c·ªôt '{text_col_name}'."); st.stop()

            if st.button("üìä X·ª≠ l√Ω File CSV (Lai gh√©p)", key="analyze_csv_hybrid"):
                if limit_enabled:
                    process_df = df.head(limit_rows_hybrid)
                    limit_info = f"{limit_rows_hybrid} d√≤ng ƒë·∫ßu ti√™n"
                    if limit_rows_hybrid <= 0:
                         st.warning("S·ªë d√≤ng gi·ªõi h·∫°n ph·∫£i > 0. ƒêang x·ª≠ l√Ω 10 d√≤ng ƒë·∫ßu."); limit_rows_hybrid = 10; process_df = df.head(10); limit_info = "10 d√≤ng ƒë·∫ßu ti√™n (ƒë√£ s·ª≠a)"
                else:
                    process_df = df; limit_info = "t·∫•t c·∫£ c√°c d√≤ng"

                total_to_process = len(process_df)
                if total_to_process == 0: st.warning("Kh√¥ng c√≥ d√≤ng n√†o ƒë·ªÉ x·ª≠ l√Ω.")
                else:
                    st.info(f"B·∫Øt ƒë·∫ßu x·ª≠ l√Ω {limit_info}...")
                    results_list = [] ; error_count = 0 ; ai_call_count = 0
                    start_batch_time = time.time()
                    progress_text = f"ƒêang x·ª≠ l√Ω 0/{total_to_process} d√≤ng..."
                    progress_bar = st.progress(0, text=progress_text)

                    for index, row in process_df.iterrows():
                        comment_text = str(row[text_col_name]) if pd.notna(row[text_col_name]) else ""
                        result_row = {"original_comment": comment_text, "sentiment": None, "ai_call_reason": None, "status": None} # Ch·ªâ l∆∞u c√°i c·∫ßn
                        if comment_text:
                            try:
                                response = requests.post(BACKEND_API_URL, json={"comment": comment_text}, timeout=180)
                                response.raise_for_status()
                                api_data = response.json()
                                result_row['sentiment'] = api_data.get('sentiment')
                                ai_reason = api_data.get('ai_call_reason', '')
                                result_row['ai_call_reason'] = ai_reason
                                if ai_reason and "ƒê·ªô tin c·∫≠y cao" not in ai_reason and "Kh√¥ng thu·ªôc TH ƒë·∫∑c bi·ªát" not in ai_reason:
                                    ai_call_count += 1
                                result_row['status'] = 'Th√†nh c√¥ng'
                            except requests.exceptions.Timeout: result_row['status'] = 'L·ªói API: Timeout'; error_count += 1
                            except requests.exceptions.RequestException as e: result_row['status'] = f'L·ªói API: {type(e).__name__}'; error_count += 1
                            except Exception as e: result_row['status'] = f'L·ªói kh√°c: {type(e).__name__}'; error_count += 1
                        else: result_row['status'] = 'B·ªè qua (r·ªóng)'
                        results_list.append(result_row)
                        progress_percentage = (index + 1) / total_to_process
                        progress_text = f"ƒêang x·ª≠ l√Ω {index + 1}/{total_to_process} d√≤ng..."
                        progress_bar.progress(progress_percentage, text=progress_text)

                    end_batch_time = time.time()
                    progress_bar.empty()
                    st.success(f"‚úÖ X·ª≠ l√Ω {total_to_process} d√≤ng ho√†n t·∫•t sau {end_batch_time - start_batch_time:.2f} gi√¢y.")

                    if results_list:
                        results_df = pd.DataFrame(results_list)
                        st.markdown("---")
                        st.subheader("üìä Th·ªëng k√™ Chung")
                        # ... (Ph·∫ßn th·ªëng k√™ v√† nh·∫≠n x√©t gi·ªØ nguy√™n nh∆∞ tr∆∞·ªõc) ...
                        col_stat1, col_stat2, col_stat3 = st.columns(3)
                        with col_stat1: st.metric("T·ªïng s·ªë d√≤ng x·ª≠ l√Ω", total_to_process)
                        with col_stat2: st.metric("S·ªë d√≤ng g·∫∑p l·ªói", error_count)
                        with col_stat3: st.metric("S·ªë d√≤ng c·∫ßn AI can thi·ªáp", ai_call_count)
                        if 'sentiment' in results_df.columns and not results_df['sentiment'].empty:
                            valid_sentiments = results_df.dropna(subset=['sentiment'])
                            sentiment_counts = valid_sentiments['sentiment'].value_counts()
                            all_labels = list(getattr(config, 'TARGET_LABEL_MAP', {}).values())
                            sentiment_counts = sentiment_counts.reindex(all_labels, fill_value=0)
                            color_map_stats = {"Ti√™u c·ª±c": '#DC143C', "Trung t√≠nh": '#FFD700', "T√≠ch c·ª±c": '#32CD32'}
                            counts_to_plot = sentiment_counts[sentiment_counts.index.isin(color_map_stats.keys())]
                            if not counts_to_plot.empty:
                                 st.markdown("---")
                                 st.subheader("üìà Ph√¢n ph·ªëi & Nh·∫≠n x√©t C·∫£m x√∫c")
                                 col_chart, col_commentary = st.columns([2, 1])
                                 with col_chart:
                                     fig_bar_batch = px.bar(counts_to_plot, x=counts_to_plot.index, y=counts_to_plot.values, labels={'x': 'C·∫£m x√∫c', 'y': 'S·ªë l∆∞·ª£ng'}, color=counts_to_plot.index, color_discrete_map=color_map_stats, text=counts_to_plot.values, height=350)
                                     fig_bar_batch.update_layout(showlegend=False, title_text="Bi·ªÉu ƒë·ªì C·∫£m x√∫c", title_x=0.5)
                                     st.plotly_chart(fig_bar_batch, use_container_width=True)
                                 with col_commentary:
                                     st.subheader("üìù Nh·∫≠n x√©t")
                                     total_valid = counts_to_plot.sum()
                                     if total_valid > 0:
                                         pos_count = counts_to_plot.get("T√≠ch c·ª±c", 0); neg_count = counts_to_plot.get("Ti√™u c·ª±c", 0); neu_count = counts_to_plot.get("Trung t√≠nh", 0)
                                         positive_perc = (pos_count / total_valid) * 100; negative_perc = (neg_count / total_valid) * 100; neutral_perc = (neu_count / total_valid) * 100
                                         st.markdown(f"- **T√≠ch c·ª±c:** {pos_count} ({positive_perc:.1f}%)")
                                         st.markdown(f"- **Trung t√≠nh:** {neu_count} ({neutral_perc:.1f}%)")
                                         st.markdown(f"- **Ti√™u c·ª±c:** {neg_count} ({negative_perc:.1f}%)")
                                         st.markdown("---")
                                         if positive_perc >= 65: st.success("**Xu h∆∞·ªõng:** R·∫•t t√≠ch c·ª±c!"); st.markdown("**G·ª£i √Ω:** Ph√°t huy ƒëi·ªÉm m·∫°nh.")
                                         elif negative_perc >= 35: st.error("**Xu h∆∞·ªõng:** C·∫ßn c·∫£i thi·ªán!"); st.markdown("**G·ª£i √Ω:** Ph√¢n t√≠ch k·ªπ b√¨nh lu·∫≠n ti√™u c·ª±c.")
                                         elif negative_perc >= 20: st.warning("**Xu h∆∞·ªõng:** C√≥ ƒëi·ªÉm c·∫ßn ch√∫ √Ω."); st.markdown("**G·ª£i √Ω:** Xem x√©t ph·∫£n h·ªìi ti√™u c·ª±c/trung t√≠nh.")
                                         else: st.info("**Xu h∆∞·ªõng:** C√¢n b·∫±ng."); st.markdown("**G·ª£i √Ω:** Duy tr√¨ v√† theo d√µi.")
                                         st.caption(f"(Tr√™n {total_valid} ph·∫£n h·ªìi h·ª£p l·ªá)")
                                     else: st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu nh·∫≠n x√©t.")
                            else: st.info("Kh√¥ng c√≥ d·ªØ li·ªáu c·∫£m x√∫c h·ª£p l·ªá.")
                        else: st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu c·∫£m x√∫c ƒë·ªÉ th·ªëng k√™.")

                        # --- N√∫t T·∫£i xu·ªëng ---
                        st.markdown("---"); st.subheader("üíæ T·∫£i xu·ªëng K·∫øt qu·∫£")
                        @st.cache_data
                        def convert_minimal_batch_df(df_to_convert):
                            cols_to_save = ["original_comment", "sentiment", "confidence", "ai_call_reason", "status"]
                            existing_cols = [col for col in cols_to_save if col in df_to_convert.columns]
                            try: return df_to_convert[existing_cols].to_csv(index=False, encoding='utf-8-sig')
                            except: return None
                        csv_minimal_output = convert_minimal_batch_df(results_df)
                        if csv_minimal_output: st.download_button(label="üì• T·∫£i K·∫øt qu·∫£ X·ª≠ l√Ω (CSV)", data=csv_minimal_output, file_name=f'ket_qua_xu_ly_{uploaded_file.name}.csv', mime='text/csv')
                        else: st.error("L·ªói t·∫°o file CSV.")

        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω file CSV: {e}")
            traceback.print_exc()


# --- Tab 3: Th√¥ng tin Model ---
# ƒê·∫£m b·∫£o kh·ªëi n√†y c√≥ n·ªôi dung th·ª•t v√†o
with tab3:
    st.header("Th√¥ng tin ƒê√°nh gi√° Model (XLM-RoBERTa)")
    st.markdown("K·∫øt qu·∫£ ƒë√°nh gi√° hi·ªáu nƒÉng tr√™n t·∫≠p d·ªØ li·ªáu ki·ªÉm th·ª≠ (test set).")

    # L·∫•y ƒë∆∞·ªùng d·∫´n an to√†n t·ª´ config
    summary_path = getattr(config, 'EVALUATION_SUMMARY_FILE', None)
    cm_path = getattr(config, 'CONFUSION_MATRIX_FILE', None)
    curves_path = getattr(config, 'TRAINING_CURVES_FILE', None)
    error_path = getattr(config, 'ERROR_ANALYSIS_FILE', None)
    report_path = getattr(config, 'CLASSIFICATION_REPORT_FILE', None) # Th√™m report path

    summary_data = None
    # ƒê·ªçc summary JSON
    if summary_path and os.path.exists(summary_path):
        try:
            with open(summary_path, 'r', encoding='utf-8') as f: summary_data = json.load(f)
        except Exception as e: st.warning(f"L·ªói ƒë·ªçc summary: {e}"); summary_data = {}
    else:
        st.info(f"Ch∆∞a c√≥ file t√≥m t·∫Øt ({summary_path or 'ƒë∆∞·ªùng d·∫´n ch∆∞a c·∫•u h√¨nh'}). Ch·∫°y evaluate.py."); summary_data = {}

    # Hi·ªÉn th·ªã Metrics
    st.subheader("üìà Ch·ªâ s·ªë Hi·ªáu nƒÉng Ch√≠nh")
    col1, col2, col3, col4 = st.columns(4)
    with col1: acc = summary_data.get('test_accuracy'); st.metric("Accuracy", f"{acc:.2%}" if acc is not None else "N/A")
    with col2: f1_w = summary_data.get('weighted_f1'); st.metric("F1 (Weighted)", f"{f1_w:.4f}" if f1_w is not None else "N/A")
    with col3: f1_m = summary_data.get('macro_f1'); st.metric("F1 (Macro)", f"{f1_m:.4f}" if f1_m is not None else "N/A")
    with col4: loss = summary_data.get('test_loss'); st.metric("Loss (Test)", f"{loss:.4f}" if loss is not None else "N/A", delta_color="inverse")

    # Hi·ªÉn th·ªã Report
    st.subheader("üìä B√°o c√°o Ph√¢n lo·∫°i")
    report_display = summary_data.get('classification_report_text')
    if report_display:
         st.text(report_display)
    elif report_path and os.path.exists(report_path): # Th·ª≠ ƒë·ªçc t·ª´ file text n·∫øu summary kh√¥ng c√≥
         try:
             with open(report_path, 'r', encoding='utf-8') as f: st.text(f.read())
         except Exception as e: st.warning(f"L·ªói ƒë·ªçc report text: {e}")
    else:
         st.info("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu b√°o c√°o.")

    # Hi·ªÉn th·ªã CM
    st.subheader("‚ùì Ma tr·∫≠n Nh·∫ßm l·∫´n")
    col_cm1, col_cm2 = st.columns([2,1])
    with col_cm1:
        if cm_path and os.path.exists(cm_path):
            try: st.image(cm_path, caption="Ma tr·∫≠n Nh·∫ßm l·∫´n")
            except Exception as e: st.warning(f"L·ªói t·∫£i ·∫£nh CM: {e}")
        else: st.info(f"Ch∆∞a c√≥ ·∫£nh CM ({cm_path or 'ƒë∆∞·ªùng d·∫´n ch∆∞a c·∫•u h√¨nh'}).")
    with col_cm2:
        st.markdown("**C√°ch ƒë·ªçc:** ƒê∆∞·ªùng ch√©o ch√≠nh l√† ƒë√∫ng.")
        if 'confusion_matrix' in summary_data and 'TARGET_LABEL_MAP' in dir(config):
             cm_list = summary_data['confusion_matrix']; labels_cm = list(config.TARGET_LABEL_MAP.values())
             st.write("**L·ªói ch√≠nh:**")
             try:
                 for i, true_label in enumerate(labels_cm):
                     for j, pred_label in enumerate(labels_cm):
                         if i < len(cm_list) and j < len(cm_list[i]) and i != j and cm_list[i][j] > 0:
                              st.caption(f"- {cm_list[i][j]} '{true_label}' -> '{pred_label}'")
             except Exception as e: print(f"L·ªói ph√¢n t√≠ch CM: {e}")

    # Hi·ªÉn th·ªã Curves
    st.subheader("üìâ Bi·ªÉu ƒë·ªì Hu·∫•n luy·ªán")
    if curves_path and os.path.exists(curves_path):
         try: st.image(curves_path, caption="Loss & Accuracy")
         except Exception as e: st.warning(f"L·ªói t·∫£i ·∫£nh curves: {e}")
    else: st.info(f"Ch∆∞a c√≥ ·∫£nh bi·ªÉu ƒë·ªì ({curves_path or 'ƒë∆∞·ªùng d·∫´n ch∆∞a c·∫•u h√¨nh'}).")

    # Hi·ªÉn th·ªã Error Analysis
    st.subheader("üö´ Ph√¢n t√≠ch L·ªói")
    if error_path and os.path.exists(error_path):
        try:
            error_df = pd.read_csv(error_path)
            st.write(f"T·ªïng c·ªông **{len(error_df)}** m·∫´u sai.")
            if not error_df.empty: st.dataframe(error_df.head(20))
            # ... (n√∫t t·∫£i file l·ªói gi·ªØ nguy√™n) ...
            @st.cache_data
            def convert_error_df(df):
                 try: return df.to_csv(index=False).encode('utf-8-sig')
                 except: return None
            csv_errors = convert_error_df(error_df)
            if csv_errors: st.download_button(label="üì• T·∫£i file l·ªói (CSV)", data=csv_errors, file_name="error_analysis.csv", mime="text/csv")

        except Exception as e: st.warning(f"L·ªói ƒë·ªçc file l·ªói ({error_path}): {e}")
    else: st.info(f"Ch∆∞a c√≥ file ph√¢n t√≠ch l·ªói ({error_path or 'ƒë∆∞·ªùng d·∫´n ch∆∞a c·∫•u h√¨nh'}).")


# --- Footer ---
st.markdown("---")
st.caption("D·ª± √°n Th·ª±c t·∫≠p - X·ª≠ l√Ω Ph·∫£n h·ªìi Kh√°ch h√†ng (Lai gh√©p) - [T√™n c·ªßa b·∫°n]")