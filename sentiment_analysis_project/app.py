# app.py (vFinal v2 - Tab 2 Ph√¢n t√≠ch & G·ª£i √Ω AI theo Product ID)

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import os
import time
import requests
import json
import traceback
from collections import Counter

import config
try:
    from visualization import plot_confusion_matrix, plot_training_history
    VIZ_AVAILABLE = True
except ImportError:
    VIZ_AVAILABLE = False
    print("C·∫£nh b√°o: Module 'visualization' kh√¥ng t√¨m th·∫•y.")

# Import th∆∞ vi·ªán Gemini v√† ki·ªÉm tra c·∫•u h√¨nh
gemini_configured_app = False
if config.GEMINI_API_KEY:
    try:
        import google.generativeai as genai
        genai.configure(api_key=config.GEMINI_API_KEY)
        gemini_configured_app = True
        print("Gemini OK (Streamlit).")
    except ImportError:
        print("C·∫£nh b√°o: google-generativeai ch∆∞a c√†i.")
    except Exception as e:
        print(f"C·∫£nh b√°o: L·ªói c·∫•u h√¨nh Gemini (Streamlit): {e}")
else:
    print("C·∫£nh b√°o: GEMINI_API_KEY ch∆∞a ƒë·∫∑t (Streamlit).")

# --- C·∫•u h√¨nh Trang ---
st.set_page_config(page_title="X·ª≠ l√Ω Ph·∫£n h·ªìi vFinal v2", page_icon="üí°", layout="wide")

# --- ƒê·ªãa ch·ªâ API Backend ---
API_HOST = getattr(config, 'API_HOST', '127.0.0.1')
API_PORT = getattr(config, 'API_PORT', 8000)
BACKEND_API_URL_SENTIMENT = f"http://{API_HOST}:{API_PORT}/sentiment/"
BACKEND_API_URL_PROCESS = f"http://{API_HOST}:{API_PORT}/process/"

# --- Giao di·ªán Ch√≠nh ---
st.title("üí° H·ªá th·ªëng Ph√¢n t√≠ch & X·ª≠ l√Ω Ph·∫£n h·ªìi Kh√°ch h√†ng (Product Aware) vFinal v2")
st.markdown("""
**Ch·ªçn c√°ch x·ª≠ l√Ω:**
- **Ph√¢n t√≠ch Nhanh:** Ch·ªâ l·∫•y c·∫£m x√∫c (nhanh, ƒë·ªçc/l∆∞u v√†o KB). *C√≥ th·ªÉ k√®m Product ID.*
- **X·ª≠ l√Ω Chi ti·∫øt:** L·∫•y c·∫£m x√∫c, g·ª£i √Ω & ph·∫£n h·ªìi AI (ƒë·ªçc/l√†m gi√†u KB & g·ªçi Gemini). *C√≥ th·ªÉ k√®m Product ID.*
- **X·ª≠ l√Ω H√†ng lo·∫°t:** Ph√¢n t√≠ch nhanh file CSV (l√†m n√≥ng KB), nh·∫≠n **ph√¢n t√≠ch c·∫£m x√∫c** v√† **g·ª£i √Ω AI** chi ti·∫øt theo t·ª´ng Product ID.
""")

# --- C√°c Tab ch·ª©c nƒÉng ---
tab1, tab2, tab3 = st.tabs(["üìù X·ª≠ l√Ω ƒê∆°n l·∫ª", "üìÇ X·ª≠ l√Ω H√†ng lo·∫°t (Theo S·∫£n ph·∫©m + AI)", "üìà Th√¥ng tin Model"])

# --- Tab 1: X·ª≠ l√Ω ƒê∆°n l·∫ª (Gi·ªØ nguy√™n, h·ªó tr·ª£ Product ID) ---
with tab1:
    st.header("Nh·∫≠p ph·∫£n h·ªìi c·∫ßn x·ª≠ l√Ω:")
    user_input_single = st.text_area("N·ªôi dung b√¨nh lu·∫≠n:", height=120, key="single_input_tab1_prod_final", placeholder="V√≠ d·ª•: Chi·∫øc √°o n√†y m√†u r·∫•t ƒë·∫πp!")
    product_id_input = st.text_input("M√£/T√™n S·∫£n ph·∫©m (T√πy ch·ªçn):", key="product_id_single_final", placeholder="V√≠ d·ª•: AO-001")

    col_btn1, col_btn2 = st.columns(2)

    def display_results_tab1(api_response, start_time, end_time, endpoint_name):
        st.markdown("---")
        st.subheader(f"K·∫øt qu·∫£ t·ª´ {endpoint_name}:")
        if not api_response:
            st.error(f"Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi h·ª£p l·ªá t·ª´ API {endpoint_name}.")
            return
        total_time = (end_time - start_time) * 1000
        api_time = api_response.get('processing_time_ms')
        source = api_response.get('source', 'N/A')
        ai_reason = api_response.get('ai_call_reason')
        product_id_rcv = api_response.get('product_id_processed')
        col_res1, col_res2 = st.columns(2)
        with col_res1:
            st.markdown("**Ph√¢n t√≠ch C·∫£m x√∫c:**")
            sentiment = api_response.get('sentiment', 'N/A')
            confidence = api_response.get('confidence')
            try:
                label_map = getattr(config, 'TARGET_LABEL_MAP', {})
                positive_label = label_map.get(2, "T√≠ch c·ª±c")
                negative_label = label_map.get(0, "Ti√™u c·ª±c")
            except:
                label_map = {}
                positive_label = "T√≠ch c·ª±c"
                negative_label = "Ti√™u c·ª±c"
            if sentiment == positive_label:
                st.success(f"**C·∫£m x√∫c:** {sentiment}")
            elif sentiment == negative_label:
                st.error(f"**C·∫£m x√∫c:** {sentiment}")
            else:
                st.warning(f"**C·∫£m x√∫c:** {sentiment}")
            if confidence is not None:
                st.metric(label="ƒê·ªô tin c·∫≠y", value=f"{confidence:.2%}")
            if product_id_rcv:
                st.caption(f"S·∫£n ph·∫©m ƒë√£ x·ª≠ l√Ω: {product_id_rcv}")
            st.caption(f"T.gian: {total_time:.0f}ms | API T.gian: {api_time:.0f}ms" if api_time else f"T.gian: {total_time:.0f}ms")
            source_text = {
                'cache': 'Cache KB',
                'cache_enriched': 'L√†m gi√†u KB',
                'new_sentiment_only': 'M·ªõi (Ch·ªâ Sentiment)',
                'new_full_process': 'M·ªõi (Full AI)',
                'error': 'L·ªói X·ª≠ l√Ω'
            }.get(source, source)
            st.caption(f"Ngu·ªìn: {source_text}")
            if ai_reason and source != 'cache':
                st.caption(f"Tr·∫°ng th√°i AI: {ai_reason}")
        with col_res2:
            st.markdown("**G·ª£i √Ω Ph·∫£n h·ªìi T·ª± ƒë·ªông (AI/Cache):**")
            generated_response = api_response.get('generated_response')
            is_valid_response = generated_response and isinstance(generated_response, str) and "L·ªói" not in generated_response and "ch∆∞a c·∫•u h√¨nh" not in generated_response and "kh√¥ng t·∫°o ra" not in generated_response
            if is_valid_response:
                st.text_area("N·ªôi dung:", value=generated_response, height=120, key=f"gen_resp_{source}_{int(time.time())}", disabled=False)
            elif generated_response:
                st.info(generated_response)
            else:
                st.info("Kh√¥ng c√≥.")
        st.markdown("---")
        st.markdown("**G·ª£i √Ω H√†nh ƒë·ªông N·ªôi b·ªô (AI/Cache):**")
        suggestions = api_response.get('suggestions')
        is_valid_suggestions = suggestions and isinstance(suggestions, list) and not any("L·ªói" in s or "ch∆∞a c·∫•u h√¨nh" in s for s in suggestions)
        if is_valid_suggestions:
            st.markdown("\n".join(f"- {s}" for s in suggestions))
        elif suggestions and isinstance(suggestions, list):
            st.info(suggestions[0])
        else:
            st.info("Kh√¥ng c√≥.")

    with col_btn1:
        if st.button("‚ö° Ph√¢n t√≠ch Nhanh (ƒê·ªçc/L∆∞u KB)", key="analyze_fast_kb_final_prod", help="L·∫•y c·∫£m x√∫c, ƒë·ªçc/l∆∞u KB. K√®m Product ID n·∫øu c√≥."):
            if user_input_single and user_input_single.strip():
                start_time = time.time()
                api_response = None
                error_message = None
                payload = {"comment": user_input_single}
                if product_id_input and product_id_input.strip():
                    payload["product_id"] = product_id_input.strip()
                with st.spinner('‚ö° ƒêang ph√¢n t√≠ch nhanh & ki·ªÉm tra KB...'):
                    try:
                        response = requests.post(BACKEND_API_URL_SENTIMENT, json=payload, timeout=30)
                        response.raise_for_status()
                        api_response = response.json()
                    except Exception as e:
                        error_message = f"L·ªói API /sentiment/: {e}"
                        traceback.print_exc()
                end_time = time.time()
                if error_message:
                    st.error(error_message)
                display_results_tab1(api_response, start_time, end_time, "/sentiment/")
            else:
                st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p b√¨nh lu·∫≠n.")

    with col_btn2:
        if st.button("‚ú® X·ª≠ l√Ω Chi ti·∫øt (KB + AI)", key="analyze_detailed_kb_final_prod", help="ƒê·ªçc KB, n·∫øu thi·∫øu -> XLM-R + Gemini -> L∆∞u/C·∫≠p nh·∫≠t KB. K√®m Product ID n·∫øu c√≥."):
            if user_input_single and user_input_single.strip():
                start_time = time.time()
                api_response = None
                error_message = None
                payload = {"comment": user_input_single}
                if product_id_input and product_id_input.strip():
                    payload["product_id"] = product_id_input.strip()
                with st.spinner('‚ú® ƒêang x·ª≠ l√Ω chi ti·∫øt...'):
                    try:
                        response = requests.post(BACKEND_API_URL_PROCESS, json=payload, timeout=180)
                        response.raise_for_status()
                        api_response = response.json()
                    except Exception as e:
                        error_message = f"L·ªói API /process/: {e}"
                        traceback.print_exc()
                end_time = time.time()
                if error_message:
                    st.error(error_message)
                    st.info("M·∫πo: Ki·ªÉm tra server API & GEMINI_API_KEY.")
                display_results_tab1(api_response, start_time, end_time, "/process/")
            else:
                st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p b√¨nh lu·∫≠n.")

# --- Tab 2: X·ª≠ l√Ω H√†ng lo·∫°t (Ph√¢n t√≠ch & G·ª£i √Ω AI theo Product ID) ---
with tab2:
    st.header("Ph√¢n t√≠ch H√†ng lo·∫°t v√† G·ª£i √Ω AI theo S·∫£n ph·∫©m")
    st.markdown("T·∫£i l√™n file CSV c√≥ c·ªôt ch·ª©a **b√¨nh lu·∫≠n** v√† c·ªôt ch·ª©a **M√£/T√™n S·∫£n ph·∫©m** ƒë·ªÉ ph√¢n t√≠ch c·∫£m x√∫c v√† nh·∫≠n g·ª£i √Ω AI chi ti·∫øt cho t·ª´ng s·∫£n ph·∫©m.")

    # L·∫•y t√™n c·ªôt t·ª´ config
    comment_col_name_cfg = getattr(config, 'TEXT_COLUMN', 'comment')
    # Th√™m √¥ nh·∫≠p t√™n c·ªôt product_id, ƒë·ªÉ tr·ªëng ban ƒë·∫ßu nh∆∞ng gi·ªØ placeholder
    product_id_col_name_input = st.text_input(
        "Nh·∫≠p t√™n c·ªôt ch·ª©a M√£/T√™n S·∫£n ph·∫©m trong file CSV c·ªßa b·∫°n:",
        placeholder="V√≠ d·ª•: product_id, Product Name, MaSP,...",
        key="product_id_col_csv"
    )

    uploaded_file_batch = st.file_uploader(
        f"Ch·ªçn file CSV (c·∫ßn c·ªôt '{comment_col_name_cfg}' v√† c·ªôt S·∫£n ph·∫©m b·∫°n v·ª´a nh·∫≠p)",
        type=["csv"],
        key="csv_product_analysis"
    )
    limit_rows_batch_prod = st.number_input(
        "Gi·ªõi h·∫°n s·ªë d√≤ng x·ª≠ l√Ω (Nh·∫≠p 0 ƒë·ªÉ x·ª≠ l√Ω t·∫•t c·∫£):",
        min_value=0,
        value=0,
        step=50,
        key="limit_rows_batch_prod",
        help="ƒê·ªÉ 0 n·∫øu mu·ªën x·ª≠ l√Ω to√†n b·ªô file."
    )

    if uploaded_file_batch is not None and product_id_col_name_input.strip():
        product_id_col_actual = product_id_col_name_input.strip()
        try:
            df_batch = None
            with st.spinner("ƒêang ƒë·ªçc CSV..."):
                try:
                    df_batch = pd.read_csv(uploaded_file_batch, encoding='utf-8-sig', low_memory=False)
                except UnicodeDecodeError:
                    df_batch = pd.read_csv(uploaded_file_batch, encoding='utf-8', low_memory=False)
                except Exception as e:
                    st.error(f"L·ªói ƒë·ªçc file: {e}")
                    st.write("N·ªôi dung file (d·∫°ng text):", uploaded_file_batch.getvalue().decode('utf-8', errors='ignore'))
                    st.stop()

            st.success(f"‚úÖ File '{uploaded_file_batch.name}' ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng! (T·ªïng {len(df_batch)} d√≤ng)")

            # Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa c·∫£ 2 c·ªôt
            if comment_col_name_cfg not in df_batch.columns:
                st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y c·ªôt b√¨nh lu·∫≠n '{comment_col_name_cfg}' trong file CSV.")
                st.stop()
            if product_id_col_actual not in df_batch.columns:
                st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y c·ªôt s·∫£n ph·∫©m '{product_id_col_actual}' trong file CSV.")
                st.stop()

            if st.button("üìä Ph√¢n t√≠ch theo S·∫£n ph·∫©m & Nh·∫≠n G·ª£i √Ω AI", key="analyze_csv_by_product"):
                # X√°c ƒë·ªãnh s·ªë d√≤ng x·ª≠ l√Ω
                if limit_rows_batch_prod > 0 and limit_rows_batch_prod < len(df_batch):
                    process_df_batch = df_batch.head(limit_rows_batch_prod)
                    limit_info_batch = f"{limit_rows_batch_prod} d√≤ng ƒë·∫ßu"
                else:
                    process_df_batch = df_batch
                    limit_info_batch = "t·∫•t c·∫£ c√°c d√≤ng"
                total_to_process_batch = len(process_df_batch)
                if total_to_process_batch == 0:
                    st.warning("Kh√¥ng c√≥ d√≤ng n√†o ƒë·ªÉ x·ª≠ l√Ω.")
                    st.stop()

                st.info(f"B·∫Øt ƒë·∫ßu ph√¢n t√≠ch c·∫£m x√∫c cho {limit_info_batch} (l∆∞u v√†o KB)...")
                results_list_batch = []
                error_count_batch = 0
                cache_hit_count = 0
                potential_ai_call_count = 0
                start_batch_run_time = time.time()
                progress_text_batch = f"Ph√¢n t√≠ch c·∫£m x√∫c 0/{total_to_process_batch} d√≤ng..."
                progress_bar_batch = st.progress(0, text=progress_text_batch)

                # L·∫•y c·∫•u h√¨nh ki·ªÉm tra AI
                conf_threshold_batch = float(getattr(config, 'CONFIDENCE_THRESHOLD', 0.80))
                check_negative_batch = bool(getattr(config, 'ALWAYS_CHECK_NEGATIVE', True))
                label_map_batch = getattr(config, 'TARGET_LABEL_MAP', {})
                negative_label_value_batch = label_map_batch.get(0, "Ti√™u c·ª±c")

                # --- B∆∞·ªõc 1: Ph√¢n t√≠ch c·∫£m x√∫c h√†ng lo·∫°t b·∫±ng API /sentiment/ ---
                for index, row in process_df_batch.iterrows():
                    comment_text = str(row[comment_col_name_cfg]) if pd.notna(row[comment_col_name_cfg]) else ""
                    product_id = str(row[product_id_col_actual]) if pd.notna(row[product_id_col_actual]) else "N/A"
                    result_row = {
                        "original_comment": comment_text,
                        "product_id": product_id,
                        "sentiment": None,
                        "confidence": None,
                        "source": None,
                        "status": None,
                        "would_call_ai": False
                    }
                    if comment_text:
                        try:
                            payload = {"comment": comment_text, "product_id": product_id}
                            response = requests.post(BACKEND_API_URL_SENTIMENT, json=payload, timeout=60)
                            response.raise_for_status()
                            api_data = response.json()
                            result_row.update({k: api_data.get(k) for k in ['sentiment', 'confidence', 'source']})
                            result_row['status'] = 'Th√†nh c√¥ng'
                            if api_data.get('source') == 'cache':
                                cache_hit_count += 1
                            # ∆Ø·ªõc t√≠nh g·ªçi AI
                            would_call = False
                            if api_data.get('source') != 'cache':
                                if api_data.get('confidence') is not None and api_data.get('confidence') < conf_threshold_batch:
                                    would_call = True
                                elif check_negative_batch and api_data.get('sentiment') == negative_label_value_batch:
                                    would_call = True
                            elif api_data.get('source') == 'cache' and (api_data.get('suggestions') is None or api_data.get('generated_response') is None):
                                would_call = True
                            result_row['would_call_ai'] = would_call
                            if would_call:
                                potential_ai_call_count += 1
                        except requests.exceptions.Timeout:
                            result_row['status'] = 'L·ªói API: Timeout'
                            error_count_batch += 1
                        except requests.exceptions.RequestException as e:
                            result_row['status'] = f'L·ªói API: {type(e).__name__}'
                            error_count_batch += 1
                        except Exception as e:
                            result_row['status'] = f'L·ªói kh√°c: {type(e).__name__}'
                            error_count_batch += 1
                    else:
                        result_row['status'] = 'B·ªè qua (r·ªóng)'
                    results_list_batch.append(result_row)
                    progress_percentage = (index + 1) / total_to_process_batch
                    progress_text_batch = f"Ph√¢n t√≠ch c·∫£m x√∫c {index + 1}/{total_to_process_batch} d√≤ng..."
                    progress_bar_batch.progress(progress_percentage, text=progress_text_batch)

                end_batch_run_time = time.time()
                progress_bar_batch.empty()
                st.success(f"‚úÖ Ph√¢n t√≠ch c·∫£m x√∫c {total_to_process_batch} d√≤ng ho√†n t·∫•t sau {end_batch_run_time - start_batch_run_time:.2f} gi√¢y.")

                # --- B∆∞·ªõc 2: T·ªïng h·ª£p k·∫øt qu·∫£ v√† G·ªçi Gemini cho t·ª´ng Product ID ---
                if results_list_batch:
                    results_df_batch = pd.DataFrame(results_list_batch)
                    st.markdown("---")
                    st.subheader("üìä Th·ªëng k√™ Chung (To√†n b·ªô File)")
                    col_b_stat1, col_b_stat2, col_b_stat3, col_b_stat4 = st.columns(4)
                    with col_b_stat1:
                        st.metric("T·ªïng d√≤ng x·ª≠ l√Ω", total_to_process_batch)
                    with col_b_stat2:
                        st.metric("S·ªë d√≤ng g·∫∑p l·ªói", error_count_batch)
                    with col_b_stat3:
                        st.metric("S·ªë l·∫ßn d√πng Cache KB", cache_hit_count)
                    with col_b_stat4:
                        st.metric("∆Ø·ªõc t√≠nh c·∫ßn G·ªçi AI*", potential_ai_call_count, help="S·ªë d√≤ng c√≥ ƒë·ªô tin c·∫≠y th·∫•p/ti√™u c·ª±c ho·∫∑c c·∫ßn l√†m gi√†u KB, s·∫Ω g·ªçi Gemini n·∫øu d√πng 'X·ª≠ l√Ω Chi ti·∫øt'.")

                    # --- Dashboard T·ªïng h·ª£p: Th·ªëng k√™ ph·∫£n h·ªìi t·ªët/x·∫•u/trung t√≠nh ---
                    st.markdown("---")
                    st.subheader("üåü Dashboard T·ªïng h·ª£p: Ph√¢n t√≠ch C·∫£m x√∫c To√†n b·ªô File")
                    
                    # L·ªçc c√°c d√≤ng ph√¢n t√≠ch th√†nh c√¥ng
                    valid_df = results_df_batch[results_df_batch['status'] == 'Th√†nh c√¥ng']
                    total_valid = len(valid_df)
                    
                    if total_valid > 0:
                        # T√≠nh s·ªë l∆∞·ª£ng t·ª´ng lo·∫°i c·∫£m x√∫c
                        sentiment_counts_total = valid_df['sentiment'].value_counts()
                        all_labels_cfg = list(getattr(config, 'TARGET_LABEL_MAP', {}).values())
                        sentiment_counts_total = sentiment_counts_total.reindex(all_labels_cfg, fill_value=0)
                        color_map_cfg = {"Ti√™u c·ª±c": '#DC143C', "Trung t√≠nh": '#FFD700', "T√≠ch c·ª±c": '#32CD32'}
                        counts_to_plot_total = sentiment_counts_total[sentiment_counts_total.index.isin(color_map_cfg.keys())]

                        # Hi·ªÉn th·ªã s·ªë li·ªáu v√† bi·ªÉu ƒë·ªì
                        col_total_chart, col_total_stats = st.columns([2, 1])
                        
                        with col_total_chart:
                            # V·∫Ω bi·ªÉu ƒë·ªì tr√≤n
                            fig_pie_total = px.pie(
                                names=counts_to_plot_total.index,
                                values=counts_to_plot_total.values,
                                title="T·ª∑ l·ªá C·∫£m x√∫c To√†n b·ªô File",
                                color=counts_to_plot_total.index,
                                color_discrete_map=color_map_cfg,
                                height=300
                            )
                            st.plotly_chart(fig_pie_total, use_container_width=True)
                        
                        with col_total_stats:
                            # T√≠nh ph·∫ßn trƒÉm
                            pos_count = counts_to_plot_total.get("T√≠ch c·ª±c", 0)
                            neg_count = counts_to_plot_total.get("Ti√™u c·ª±c", 0)
                            neu_count = counts_to_plot_total.get("Trung t√≠nh", 0)
                            pos_p = (pos_count / total_valid) * 100 if total_valid > 0 else 0
                            neg_p = (neg_count / total_valid) * 100 if total_valid > 0 else 0
                            neu_p = (neu_count / total_valid) * 100 if total_valid > 0 else 0

                            st.markdown("**Th·ªëng k√™ Ph·∫£n h·ªìi:**")
                            st.markdown(f"- **Ph·∫£n h·ªìi T·ªët (T√≠ch c·ª±c):** {pos_count} ({pos_p:.1f}%)")
                            st.markdown(f"- **Ph·∫£n h·ªìi X·∫•u (Ti√™u c·ª±c):** {neg_count} ({neg_p:.1f}%)")
                            st.markdown(f"- **Ph·∫£n h·ªìi Trung t√≠nh:** {neu_count} ({neu_p:.1f}%)")
                            st.markdown("---")
                            st.markdown("**Nh·∫≠n x√©t T·ªïng quan:**")
                            if pos_p >= 65:
                                st.success("Ph·∫ßn l·ªõn ph·∫£n h·ªìi l√† T√≠ch c·ª±c, cho th·∫•y kh√°ch h√†ng h√†i l√≤ng.")
                            elif neg_p >= 35:
                                st.error("T·ª∑ l·ªá ph·∫£n h·ªìi Ti√™u c·ª±c cao, c·∫ßn xem x√©t v√† c·∫£i thi·ªán ngay.")
                            elif neg_p >= 20:
                                st.warning("T·ª∑ l·ªá ph·∫£n h·ªìi Ti√™u c·ª±c ƒë√°ng ch√∫ √Ω, n√™n ki·ªÉm tra chi ti·∫øt.")
                            else:
                                st.info("Ph·∫£n h·ªìi t∆∞∆°ng ƒë·ªëi c√¢n b·∫±ng, c·∫ßn theo d√µi th√™m.")
                    else:
                        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ hi·ªÉn th·ªã Dashboard T·ªïng h·ª£p.")

                    # --- Hi·ªÉn th·ªã Ph√¢n t√≠ch theo t·ª´ng Product ID ---
                    st.markdown("---")
                    st.subheader("üíé Ph√¢n t√≠ch & G·ª£i √Ω AI theo t·ª´ng S·∫£n ph·∫©m")
                    all_products = results_df_batch[results_df_batch['status'] == 'Th√†nh c√¥ng']['product_id'].unique()

                    if not all_products.size:
                        st.warning("Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng ƒë·ªÉ ph√¢n t√≠ch.")
                    else:
                        for prod_id in all_products:
                            with st.expander(f"K·∫øt qu·∫£ cho S·∫£n ph·∫©m: **{prod_id}**"):
                                prod_df = results_df_batch[(results_df_batch['product_id'] == prod_id) & (results_df_batch['status'] == 'Th√†nh c√¥ng')]
                                if prod_df.empty:
                                    st.write("Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá cho s·∫£n ph·∫©m n√†y.")
                                    continue

                                st.markdown(f"**T·ªïng s·ªë ph·∫£n h·ªìi cho s·∫£n ph·∫©m n√†y:** {len(prod_df)}")
                                sentiment_counts_prod = prod_df['sentiment'].value_counts()
                                all_labels_cfg = list(getattr(config, 'TARGET_LABEL_MAP', {}).values())
                                sentiment_counts_prod = sentiment_counts_prod.reindex(all_labels_cfg, fill_value=0)
                                color_map_cfg = {"Ti√™u c·ª±c": '#DC143C', "Trung t√≠nh": '#FFD700', "T√≠ch c·ª±c": '#32CD32'}
                                counts_to_plot_prod = sentiment_counts_prod[sentiment_counts_prod.index.isin(color_map_cfg.keys())]

                                if not counts_to_plot_prod.empty:
                                    col_p_chart, col_p_stats = st.columns([2, 1])
                                    with col_p_chart:
                                        fig_bar_prod = px.bar(
                                            counts_to_plot_prod,
                                            x=counts_to_plot_prod.index,
                                            y=counts_to_plot_prod.values,
                                            labels={'x': 'C·∫£m x√∫c', 'y': 'S·ªë l∆∞·ª£ng'},
                                            color=counts_to_plot_prod.index,
                                            color_discrete_map=color_map_cfg,
                                            text=counts_to_plot_prod.values,
                                            height=300
                                        )
                                        fig_bar_prod.update_layout(showlegend=False, title_text=f"C·∫£m x√∫c cho SP: {prod_id}", title_x=0.5)
                                        st.plotly_chart(fig_bar_prod, use_container_width=True)
                                    with col_p_stats:
                                        total_valid_prod = counts_to_plot_prod.sum()
                                        if total_valid_prod > 0:
                                            pos_p = (counts_to_plot_prod.get("T√≠ch c·ª±c", 0) / total_valid_prod) * 100
                                            neg_p = (counts_to_plot_prod.get("Ti√™u c·ª±c", 0) / total_valid_prod) * 100
                                            neu_p = (counts_to_plot_prod.get("Trung t√≠nh", 0) / total_valid_prod) * 100
                                            st.markdown("**Ph√¢n ph·ªëi C·∫£m x√∫c:**")
                                            st.markdown(f"- **T√≠ch c·ª±c:** {counts_to_plot_prod.get('T√≠ch c·ª±c', 0)} ({pos_p:.1f}%)")
                                            st.markdown(f"- **Trung t√≠nh:** {counts_to_plot_prod.get('Trung t√≠nh', 0)} ({neu_p:.1f}%)")
                                            st.markdown(f"- **Ti√™u c·ª±c:** {counts_to_plot_prod.get('Ti√™u c·ª±c', 0)} ({neg_p:.1f}%)")
                                            st.markdown("---")
                                            st.markdown("**Xu h∆∞·ªõng ch√≠nh:**")
                                            if pos_p >= 65:
                                                st.success("-> Ph·∫ßn l·ªõn ph·∫£n h·ªìi l√† T√≠ch c·ª±c.")
                                            elif neg_p >= 35:
                                                st.error("-> T·ª∑ l·ªá Ti√™u c·ª±c r·∫•t cao, c·∫ßn h√†nh ƒë·ªông ngay.")
                                            elif neg_p >= 20:
                                                st.warning("-> T·ª∑ l·ªá Ti√™u c·ª±c ƒë√°ng ch√∫ √Ω, c·∫ßn xem x√©t.")
                                            else:
                                                st.info("-> T·ª∑ l·ªá c·∫£m x√∫c t∆∞∆°ng ƒë·ªëi c√¢n b·∫±ng.")
                                            st.markdown("---")

                                            # G·ªçi Gemini cho t·ª´ng s·∫£n ph·∫©m
                                            st.markdown("**G·ª£i √Ω H√†nh ƒë·ªông (AI):**")
                                            if gemini_configured_app:
                                                with st.spinner(f"ƒêang l·∫•y g·ª£i √Ω AI cho s·∫£n ph·∫©m {prod_id}..."):
                                                    prompt_prod_summary = f"""Ph√¢n t√≠ch c·∫£m x√∫c cho s·∫£n ph·∫©m '{prod_id}': T√≠ch c·ª±c {pos_p:.1f}%, Trung t√≠nh {neu_p:.1f}%, Ti√™u c·ª±c {neg_p:.1f}%.
ƒê·ªÅ xu·∫•t 2-3 h√†nh ƒë·ªông c·ª• th·ªÉ cho s·∫£n ph·∫©m n√†y. ƒê·ªãnh d·∫°ng: danh s√°ch g·∫°ch ƒë·∫ßu d√≤ng."""
                                                    try:
                                                        model_gen_prod = genai.GenerativeModel('gemini-1.5-flash')
                                                        response_gen_prod = model_gen_prod.generate_content(prompt_prod_summary)
                                                        prod_suggestions = response_gen_prod.text.strip().split('\n')
                                                        if prod_suggestions:
                                                            for sugg in prod_suggestions:
                                                                if sugg.strip():
                                                                    st.markdown(f"- {sugg.strip().lstrip('-* ')}")
                                                        else:
                                                            st.info("AI kh√¥ng ƒë∆∞a ra g·ª£i √Ω.")
                                                    except Exception as gemini_e_prod:
                                                        st.warning(f"L·ªói g·ªçi AI cho SP {prod_id}: {gemini_e_prod}")
                                            else:
                                                st.info("Gemini ch∆∞a c·∫•u h√¨nh. S·ª≠ d·ª•ng g·ª£i √Ω m·∫´u.")
                                        else:
                                            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu c·∫£m x√∫c h·ª£p l·ªá cho s·∫£n ph·∫©m n√†y.")
                                else:
                                    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu c·∫£m x√∫c h·ª£p l·ªá ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì cho s·∫£n ph·∫©m n√†y.")
                    # --- N√∫t T·∫£i xu·ªëng ---
                    st.markdown("---")
                    st.subheader("üíæ T·∫£i xu·ªëng K·∫øt qu·∫£ Ph√¢n t√≠ch H√†ng lo·∫°t")
                    @st.cache_data
                    def convert_batch_product_df(df_to_convert):
                        cols = ["original_comment", "product_id", "sentiment", "confidence", "source", "status", "would_call_ai"]
                        existing = [c for c in cols if c in df_to_convert.columns]
                        try:
                            return df_to_convert[existing].to_csv(index=False, encoding='utf-8-sig')
                        except:
                            return None
                    csv_batch_prod_output = convert_batch_product_df(results_df_batch)
                    if csv_batch_prod_output:
                        st.download_button(
                            label="üì• T·∫£i K·∫øt qu·∫£ (CSV)",
                            data=csv_batch_prod_output,
                            file_name=f'ket_qua_batch_{uploaded_file_batch.name}.csv',
                            mime='text/csv'
                        )
                    else:
                        st.error("L·ªói t·∫°o file CSV.")
                else:
                    st.warning("Kh√¥ng c√≥ d√≤ng n√†o ƒë∆∞·ª£c x·ª≠ l√Ω.")
        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω file CSV: {e}")
            traceback.print_exc()

# --- Tab 3: Th√¥ng tin Model (Gi·ªØ nguy√™n) ---
with tab3:
    st.header("Th√¥ng tin ƒê√°nh gi√° Model (XLM-RoBERTa)")
    st.markdown("Ph·∫ßn n√†y hi·ªÉn th·ªã c√°c s·ªë li·ªáu ƒë√°nh gi√° v√† bi·ªÉu ƒë·ªì li√™n quan ƒë·∫øn hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh XLM-RoBERTa ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ph√¢n t√≠ch c·∫£m x√∫c.")
    if VIZ_AVAILABLE:
        st.subheader("üìä Bi·ªÉu ƒë·ªì Hi·ªáu su·∫•t")
        try:
            confusion_fig = plot_confusion_matrix()
            if confusion_fig:
                st.plotly_chart(confusion_fig, use_container_width=True)
            history_fig = plot_training_history()
            if history_fig:
                st.plotly_chart(history_fig, use_container_width=True)
        except Exception as e:
            st.error(f"L·ªói khi t·∫°o bi·ªÉu ƒë·ªì: {e}")
    else:
        st.warning("Kh√¥ng th·ªÉ t·∫£i module visualization. Vui l√≤ng ki·ªÉm tra file visualization.py.")

    st.subheader("üìà S·ªë li·ªáu Hi·ªáu su·∫•t")
    st.markdown("D∆∞·ªõi ƒë√¢y l√† c√°c s·ªë li·ªáu hi·ªáu su·∫•t m·∫´u (c·∫ßn thay th·∫ø b·∫±ng d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ m√¥ h√¨nh):")
    col_metrics1, col_metrics2, col_metrics3 = st.columns(3)
    with col_metrics1:
        st.metric("Accuracy", "85%")
    with col_metrics2:
        st.metric("F1-Score (T√≠ch c·ª±c)", "0.88")
    with col_metrics3:
        st.metric("F1-Score (Ti√™u c·ª±c)", "0.82")

# --- Footer ---
st.markdown("---")
st.caption("D·ª± √°n Th·ª±c t·∫≠p - X·ª≠ l√Ω Ph·∫£n h·ªìi Kh√°ch h√†ng - [Nguy·ªÖn Tr·∫ßn Ho√†ng Th·ªãnh]")