# app.py (vFinal v2 - Tab 2 Nh·∫≠n x√©t r√µ r√†ng & Th·ªëng k√™ AI ch·ªân chu)

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import os
import time
import requests
import json
import traceback
from collections import Counter

import config
try: from visualization import plot_confusion_matrix, plot_training_history; VIZ_AVAILABLE = True
except ImportError: VIZ_AVAILABLE = False; print("C·∫£nh b√°o: Module 'visualization' kh√¥ng t√¨m th·∫•y.")

# Import th∆∞ vi·ªán Gemini v√† ki·ªÉm tra c·∫•u h√¨nh
gemini_configured_app = False
if config.GEMINI_API_KEY:
    try: import google.generativeai as genai; genai.configure(api_key=config.GEMINI_API_KEY); gemini_configured_app = True; print("Gemini OK (Streamlit).")
    except ImportError: print("C·∫£nh b√°o: google-generativeai ch∆∞a c√†i.")
    except Exception as e: print(f"C·∫£nh b√°o: L·ªói c·∫•u h√¨nh Gemini (Streamlit): {e}")
else: print("C·∫£nh b√°o: GEMINI_API_KEY ch∆∞a ƒë·∫∑t (Streamlit).")


# --- C·∫•u h√¨nh Trang ---
st.set_page_config(page_title="X·ª≠ l√Ω Ph·∫£n h·ªìi vFinal", page_icon="üí°", layout="wide")

# --- ƒê·ªãa ch·ªâ API Backend ---
API_HOST = getattr(config, 'API_HOST', '127.0.0.1')
API_PORT = getattr(config, 'API_PORT', 8000)
BACKEND_API_URL_SENTIMENT = f"http://{API_HOST}:{API_PORT}/sentiment/"
BACKEND_API_URL_PROCESS = f"http://{API_HOST}:{API_PORT}/process/"

# --- Giao di·ªán Ch√≠nh ---
st.title("üí° H·ªá th·ªëng Ph√¢n t√≠ch & X·ª≠ l√Ω Ph·∫£n h·ªìi Kh√°ch h√†ng")
st.markdown("""
**Ch·ªçn c√°ch x·ª≠ l√Ω:**
- **Ph√¢n t√≠ch Nhanh:** Ch·ªâ l·∫•y c·∫£m x√∫c (nhanh, ƒë·ªçc/l∆∞u v√†o KB).
- **X·ª≠ l√Ω Chi ti·∫øt:** L·∫•y c·∫£m x√∫c, g·ª£i √Ω & ph·∫£n h·ªìi AI (ƒë·ªçc/l√†m gi√†u KB & g·ªçi Gemini).
- **X·ª≠ l√Ω H√†ng lo·∫°t:** Ph√¢n t√≠ch nhanh to√†n b·ªô file CSV (l√†m n√≥ng KB), nh·∫≠n **nh·∫≠n x√©t/xu h∆∞·ªõng** v√† **g·ª£i √Ω chung** t·ª´ AI.
""")

# --- C√°c Tab ch·ª©c nƒÉng ---
tab1, tab2, tab3 = st.tabs(["üìù X·ª≠ l√Ω ƒê∆°n l·∫ª", "üìÇ X·ª≠ l√Ω H√†ng lo·∫°t (Nhanh + AI T·ªïng h·ª£p)", "üìà Th√¥ng tin Model"])

# --- Tab 1: X·ª≠ l√Ω ƒê∆°n l·∫ª (Gi·ªØ nguy√™n) ---
with tab1:
    # ... (Code Tab 1 gi·ªØ nguy√™n) ...
    st.header("Nh·∫≠p ph·∫£n h·ªìi c·∫ßn x·ª≠ l√Ω:")
    user_input_single = st.text_area("Nh·∫≠p vƒÉn b·∫£n...", height=150, key="single_input_tab1_final", placeholder="...")
    col_btn1, col_btn2 = st.columns(2)
    def display_results(api_response, start_time, end_time, endpoint_name):
        # ... (H√†m display_results gi·ªØ nguy√™n) ...
        st.markdown("---"); st.subheader(f"K·∫øt qu·∫£ t·ª´ {endpoint_name}:")
        if not api_response: st.error(f"Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi h·ª£p l·ªá t·ª´ API {endpoint_name}."); return
        total_time = (end_time - start_time) * 1000; api_time = api_response.get('processing_time_ms'); source = api_response.get('source', 'N/A'); ai_reason = api_response.get('ai_call_reason')
        col_res1, col_res2 = st.columns(2)
        with col_res1:
            st.markdown("**Ph√¢n t√≠ch C·∫£m x√∫c:**"); sentiment = api_response.get('sentiment', 'N/A'); confidence = api_response.get('confidence')
            try: label_map = getattr(config, 'TARGET_LABEL_MAP', {}); positive_label = label_map.get(2, "T√≠ch c·ª±c"); negative_label = label_map.get(0, "Ti√™u c·ª±c");
            except: label_map={}; positive_label="T√≠ch c·ª±c"; negative_label="Ti√™u c·ª±c"
            if sentiment == positive_label: st.success(f"**C·∫£m x√∫c:** {sentiment}")
            elif sentiment == negative_label: st.error(f"**C·∫£m x√∫c:** {sentiment}")
            else: st.warning(f"**C·∫£m x√∫c:** {sentiment}")
            if confidence is not None: st.metric(label="ƒê·ªô tin c·∫≠y", value=f"{confidence:.2%}")
            st.caption(f"T.gian: {total_time:.0f}ms | API T.gian: {api_time:.0f}ms" if api_time else f"T.gian: {total_time:.0f}ms")
            source_text = {'cache':'Cache KB', 'cache_enriched':'L√†m gi√†u KB', 'new_sentiment_only':'M·ªõi (Ch·ªâ Sentiment)', 'new_full_process':'M·ªõi (Full AI)', 'error':'L·ªói X·ª≠ l√Ω'}.get(source, source)
            st.caption(f"Ngu·ªìn: {source_text}")
            if ai_reason and source != 'cache': st.caption(f"Tr·∫°ng th√°i AI: {ai_reason}")
        with col_res2:
            st.markdown("**G·ª£i √Ω Ph·∫£n h·ªìi T·ª± ƒë·ªông (AI/Cache):**"); generated_response = api_response.get('generated_response')
            is_valid_response = generated_response and isinstance(generated_response, str) and "L·ªói" not in generated_response and "ch∆∞a c·∫•u h√¨nh" not in generated_response and "kh√¥ng t·∫°o ra" not in generated_response
            if is_valid_response: st.text_area("N·ªôi dung:", value=generated_response, height=120, key=f"gen_resp_{source}_{int(time.time())}", disabled=False)
            elif generated_response: st.info(generated_response)
            else: st.info("Kh√¥ng c√≥.")
        st.markdown("---"); st.markdown("**G·ª£i √Ω H√†nh ƒë·ªông N·ªôi b·ªô (AI/Cache):**"); suggestions = api_response.get('suggestions')
        is_valid_suggestions = suggestions and isinstance(suggestions, list) and not any("L·ªói" in s or "ch∆∞a c·∫•u h√¨nh" in s for s in suggestions)
        if is_valid_suggestions: st.markdown("\n".join(f"- {s}" for s in suggestions))
        elif suggestions and isinstance(suggestions, list): st.info(suggestions[0])
        else: st.info("Kh√¥ng c√≥.")

    with col_btn1: # N√∫t Ph√¢n t√≠ch nhanh
        if st.button("‚ö° Ph√¢n t√≠ch Nhanh (ƒê·ªçc/L∆∞u KB)", key="analyze_fast_kb_final", help="L·∫•y c·∫£m x√∫c (local), ƒë·ªçc/l∆∞u KB."):
            if user_input_single and user_input_single.strip():
                start_time = time.time(); api_response = None; error_message = None
                with st.spinner('‚ö° ƒêang ph√¢n t√≠ch nhanh & ki·ªÉm tra KB...'):
                    try: response = requests.post(BACKEND_API_URL_SENTIMENT, json={"comment": user_input_single}, timeout=30); response.raise_for_status(); api_response = response.json()
                    except Exception as e: error_message = f"L·ªói g·ªçi API /sentiment/: {e}"; traceback.print_exc()
                end_time = time.time()
                if error_message: st.error(error_message)
                display_results(api_response, start_time, end_time, "/sentiment/")
            else: st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p vƒÉn b·∫£n.")

    with col_btn2: # N√∫t X·ª≠ l√Ω chi ti·∫øt
        if st.button("‚ú® X·ª≠ l√Ω Chi ti·∫øt (KB + AI)", key="analyze_detailed_kb_final", help="ƒê·ªçc KB, n·∫øu thi·∫øu AI -> Model + Gemini -> L∆∞u/C·∫≠p nh·∫≠t KB."):
            if user_input_single and user_input_single.strip():
                start_time = time.time(); api_response = None; error_message = None
                with st.spinner('‚ú® ƒêang x·ª≠ l√Ω chi ti·∫øt...'):
                    try: response = requests.post(BACKEND_API_URL_PROCESS, json={"comment": user_input_single}, timeout=180); response.raise_for_status(); api_response = response.json()
                    except Exception as e: error_message = f"L·ªói g·ªçi API /process/: {e}"; traceback.print_exc()
                end_time = time.time()
                if error_message: st.error(error_message); st.info("M·∫πo: Ki·ªÉm tra server API & GEMINI_API_KEY.")
                display_results(api_response, start_time, end_time, "/process/")
            else: st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p vƒÉn b·∫£n.")


# --- Tab 2: X·ª≠ l√Ω H√†ng lo·∫°t (CSV - C·∫≠p nh·∫≠t Th·ªëng k√™ & Nh·∫≠n x√©t) ---
with tab2:
    st.header("T·∫£i l√™n file CSV ƒë·ªÉ Ph√¢n t√≠ch Nhanh & Nh·∫≠n G·ª£i √Ω Chung")
    st.markdown("Ch·ª©c nƒÉng n√†y s·∫Ω ph√¢n t√≠ch c·∫£m x√∫c t·ª´ng d√≤ng b·∫±ng model local (l∆∞u v√†o KB), sau ƒë√≥ **g·ªçi AI m·ªôt l·∫ßn** ƒë·ªÉ ƒë∆∞a ra nh·∫≠n x√©t, xu h∆∞·ªõng v√† g·ª£i √Ω h√†nh ƒë·ªông chung d·ª±a tr√™n k·∫øt qu·∫£ t·ªïng h·ª£p.")
    text_col_name = getattr(config, 'TEXT_COLUMN', 'comment')
    uploaded_file_batch = st.file_uploader(f"Ch·ªçn file CSV (c·ªôt '{text_col_name}')", type=["csv"], key="csv_local_kb_final_v3")
    limit_rows_batch = st.number_input(
        "Gi·ªõi h·∫°n s·ªë d√≤ng x·ª≠ l√Ω (Nh·∫≠p 0 ƒë·ªÉ x·ª≠ l√Ω t·∫•t c·∫£):", min_value=0, value=0,  # M·∫∑c ƒë·ªãnh 0
        step=50, key="limit_rows_batch_final_v3", help="ƒê·ªÉ 0 n·∫øu mu·ªën x·ª≠ l√Ω to√†n b·ªô file."
    )

    if uploaded_file_batch is not None:
        try:
            df_batch = None
            with st.spinner("ƒêang ƒë·ªçc CSV..."):
                try:
                    df_batch = pd.read_csv(uploaded_file_batch, encoding='utf-8-sig', low_memory=False)
                except:
                    df_batch = pd.read_csv(uploaded_file_batch, encoding='utf-8', low_memory=False)
            st.success(f"‚úÖ ƒê√£ t·∫£i file '{uploaded_file_batch.name}' ({len(df_batch)} d√≤ng).")
            if text_col_name not in df_batch.columns:
                st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y c·ªôt '{text_col_name}'.")
                st.stop()

            if st.button("üìä Ph√¢n t√≠ch & Nh·∫≠n G·ª£i √Ω Chung (H√†ng lo·∫°t)", key="analyze_csv_local_kb_final_v3"):
                if limit_rows_batch > 0 and limit_rows_batch < len(df_batch):
                    process_df_batch = df_batch.head(limit_rows_batch)
                    limit_info_batch = f"{limit_rows_batch} d√≤ng ƒë·∫ßu"
                else:
                    process_df_batch = df_batch
                    limit_info_batch = "t·∫•t c·∫£ c√°c d√≤ng"
                total_to_process_batch = len(process_df_batch)
                if total_to_process_batch == 0:
                    st.warning("Kh√¥ng c√≥ d√≤ng n√†o ƒë·ªÉ x·ª≠ l√Ω.")
                    st.stop()

                st.info(f"B·∫Øt ƒë·∫ßu ph√¢n t√≠ch nhanh & l∆∞u KB cho {limit_info_batch}...")
                results_list_batch = []
                error_count_batch = 0
                cache_hit_count = 0
                potential_ai_call_count = 0
                start_batch_run_time = time.time()
                progress_text_batch = f"ƒêang x·ª≠ l√Ω 0/{total_to_process_batch} d√≤ng..."
                progress_bar_batch = st.progress(0, text=progress_text_batch)

                # L·∫•y c·∫•u h√¨nh ki·ªÉm tra AI
                conf_threshold_batch = float(getattr(config, 'CONFIDENCE_THRESHOLD', 0.80))
                check_negative_batch = bool(getattr(config, 'ALWAYS_CHECK_NEGATIVE', True))
                label_map_batch = getattr(config, 'TARGET_LABEL_MAP', {})
                negative_label_value_batch = label_map_batch.get(0, "Ti√™u c·ª±c")

                # --- V√≤ng l·∫∑p X·ª≠ l√Ω T·ª´ng D√≤ng ---
                for index, row in process_df_batch.iterrows():
                    comment_text_batch = str(row[text_col_name]) if pd.notna(row[text_col_name]) else ""
                    result_row_batch = {"original_comment": comment_text_batch, "sentiment": None, "confidence": None, "source": None, "status": None, "would_call_ai": False}
                    if comment_text_batch:
                        try:
                            response = requests.post(BACKEND_API_URL_SENTIMENT, json={"comment": comment_text_batch}, timeout=60)
                            response.raise_for_status()
                            api_data = response.json()
                            sentiment_res = api_data.get('sentiment')
                            conf_res = api_data.get('confidence')
                            source_res = api_data.get('source')
                            result_row_batch.update({'sentiment': sentiment_res, 'confidence': conf_res, 'source': source_res, 'status': 'Th√†nh c√¥ng'})
                            if source_res == 'cache':
                                cache_hit_count += 1
                            # ∆Ø·ªõc t√≠nh g·ªçi AI (ngay c·∫£ khi ƒë·ªçc t·ª´ cache nh∆∞ng thi·∫øu AI)
                            would_call = False
                            if source_res != 'cache':
                                if conf_res is not None and conf_res < conf_threshold_batch:
                                    would_call = True
                                elif check_negative_batch and sentiment_res == negative_label_value_batch:
                                    would_call = True
                            elif source_res == 'cache' and (api_data.get('suggestions') is None or api_data.get('generated_response') is None):
                                would_call = True  # C·∫ßn l√†m gi√†u KB
                            result_row_batch['would_call_ai'] = would_call
                            if would_call:
                                potential_ai_call_count += 1
                        except requests.exceptions.Timeout:
                            result_row_batch['status'] = 'L·ªói API: Timeout'
                            error_count_batch += 1
                        except requests.exceptions.RequestException as e:
                            result_row_batch['status'] = f'L·ªói API: {type(e).__name__}'
                            error_count_batch += 1
                        except Exception as e:
                            result_row_batch['status'] = f'L·ªói kh√°c: {type(e).__name__}'
                            error_count_batch += 1
                    else:
                        result_row_batch['status'] = 'B·ªè qua (r·ªóng)'
                    results_list_batch.append(result_row_batch)
                    progress_percentage = (index + 1) / total_to_process_batch
                    progress_text_batch = f"ƒêang x·ª≠ l√Ω {index + 1}/{total_to_process_batch} d√≤ng..."
                    progress_bar_batch.progress(progress_percentage, text=progress_text_batch)
                progress_bar_batch.empty()
                end_batch_run_time = time.time()
                st.success(f"‚úÖ Ph√¢n t√≠ch {total_to_process_batch} d√≤ng ho√†n t·∫•t sau {end_batch_run_time - start_batch_run_time:.2f} gi√¢y.")

                # --- Hi·ªÉn th·ªã K·∫øt qu·∫£ T·ªïng h·ª£p ---
                if results_list_batch:
                    results_df_batch = pd.DataFrame(results_list_batch)
                    st.markdown("---")
                    st.subheader("üìä Th·ªëng k√™ Chung")

                    # *** C·∫¨P NH·∫¨T C·ªòT TH·ªêNG K√ä ***
                    col_b_stat1, col_b_stat2, col_b_stat3, col_b_stat4 = st.columns(4)
                    with col_b_stat1:
                        st.metric("T·ªïng d√≤ng x·ª≠ l√Ω", total_to_process_batch)
                    with col_b_stat2:
                        st.metric("S·ªë d√≤ng g·∫∑p l·ªói", error_count_batch)
                    with col_b_stat3:
                        st.metric("S·ªë l·∫ßn d√πng Cache KB", cache_hit_count)
                    with col_b_stat4:
                        st.metric("∆Ø·ªõc t√≠nh c·∫ßn G·ªçi AI*", potential_ai_call_count, help="S·ªë d√≤ng c√≥ ƒë·ªô tin c·∫≠y th·∫•p/ti√™u c·ª±c ho·∫∑c c·∫ßn l√†m gi√†u KB, s·∫Ω g·ªçi Gemini n·∫øu d√πng 'X·ª≠ l√Ω Chi ti·∫øt'.")

                    # Bi·ªÉu ƒë·ªì + Nh·∫≠n x√©t
                    if 'sentiment' in results_df_batch.columns and not results_df_batch['sentiment'].empty:
                        valid_sentiments_b = results_df_batch.dropna(subset=['sentiment'])
                        sentiment_counts_b = valid_sentiments_b['sentiment'].value_counts()
                        all_labels_b = list(getattr(config, 'TARGET_LABEL_MAP', {}).values())
                        sentiment_counts_b = sentiment_counts_b.reindex(all_labels_b, fill_value=0)
                        color_map_stats_b = {"Ti√™u c·ª±c": '#DC143C', "Trung t√≠nh": '#FFD700', "T√≠ch c·ª±c": '#32CD32'}
                        counts_to_plot_b = sentiment_counts_b[sentiment_counts_b.index.isin(color_map_stats_b.keys())]
                        if not counts_to_plot_b.empty:
                            st.markdown("---")
                            st.subheader("üìà Ph√¢n ph·ªëi & Nh·∫≠n x√©t T·ªïng quan")
                            col_chart, col_commentary = st.columns([2, 1])
                            with col_chart:
                                fig_bar_b = px.bar(counts_to_plot_b, x=counts_to_plot_b.index, y=counts_to_plot_b.values, labels={'x': 'C·∫£m x√∫c', 'y': 'S·ªë l∆∞·ª£ng'}, color=counts_to_plot_b.index, color_discrete_map=color_map_stats_b, text=counts_to_plot_b.values, height=350)
                                fig_bar_b.update_layout(showlegend=False, title_text="Bi·ªÉu ƒë·ªì C·∫£m x√∫c", title_x=0.5)
                                st.plotly_chart(fig_bar_b, use_container_width=True)
                            with col_commentary:
                                st.subheader("üìù Nh·∫≠n x√©t & G·ª£i √Ω")
                                total_valid = counts_to_plot_b.sum()
                                if total_valid > 0:
                                    pos_count = counts_to_plot_b.get("T√≠ch c·ª±c", 0)
                                    neg_count = counts_to_plot_b.get("Ti√™u c·ª±c", 0)
                                    neu_count = counts_to_plot_b.get("Trung t√≠nh", 0)
                                    positive_perc = (pos_count / total_valid) * 100
                                    negative_perc = (neg_count / total_valid) * 100
                                    neutral_perc = (neu_count / total_valid) * 100

                                    # *** NH·∫¨N X√âT R√ï R√ÄNG H∆†N ***
                                    st.markdown("**Ph√¢n ph·ªëi C·∫£m x√∫c:**")
                                    st.markdown(f"- **T√≠ch c·ª±c:** {pos_count} ({positive_perc:.1f}%)")
                                    st.markdown(f"- **Trung t√≠nh:** {neu_count} ({neutral_perc:.1f}%)")
                                    st.markdown(f"- **Ti√™u c·ª±c:** {neg_count} ({negative_perc:.1f}%)")
                                    st.markdown("---")
                                    st.markdown("**Xu h∆∞·ªõng ch√≠nh:**")
                                    if positive_perc >= 65:
                                        st.success("-> Ph·∫ßn l·ªõn ph·∫£n h·ªìi l√† T√≠ch c·ª±c.")
                                    elif negative_perc >= 35:
                                        st.error("-> T·ª∑ l·ªá Ti√™u c·ª±c r·∫•t cao, c·∫ßn h√†nh ƒë·ªông ngay.")
                                    elif negative_perc >= 20:
                                        st.warning("-> T·ª∑ l·ªá Ti√™u c·ª±c ƒë√°ng ch√∫ √Ω, c·∫ßn xem x√©t.")
                                    else:
                                        st.info("-> T·ª∑ l·ªá c·∫£m x√∫c t∆∞∆°ng ƒë·ªëi c√¢n b·∫±ng.")
                                    st.markdown("---")

                                    # G·ªçi Gemini 1 l·∫ßn l·∫•y g·ª£i √Ω chung
                                    st.markdown("**G·ª£i √Ω H√†nh ƒë·ªông T·ªïng th·ªÉ (AI):**")
                                    if gemini_configured_app:
                                        with st.spinner("ƒêang l·∫•y g·ª£i √Ω t·ª´ AI..."):
                                            prompt_summary = f"""Ph√¢n t√≠ch t·ª∑ l·ªá c·∫£m x√∫c t·ª´ ph·∫£n h·ªìi kh√°ch h√†ng: T√≠ch c·ª±c {positive_perc:.1f}%, Trung t√≠nh {neutral_perc:.1f}%, Ti√™u c·ª±c {negative_perc:.1f}%. ƒê·ªÅ xu·∫•t 3-5 h√†nh ƒë·ªông chi·∫øn l∆∞·ª£c t·ªïng th·ªÉ. ƒê·ªãnh d·∫°ng: danh s√°ch g·∫°ch ƒë·∫ßu d√≤ng."""
                                            try:
                                                model_gen = genai.GenerativeModel('gemini-1.5-flash')
                                                response_gen = model_gen.generate_content(prompt_summary)
                                                summary_suggestions = response_gen.text.strip().split('\n')
                                            except Exception as gemini_e:
                                                st.warning(f"L·ªói g·ªçi AI: {gemini_e}")
                                                summary_suggestions = []
                                            if summary_suggestions:
                                                for sugg in summary_suggestions:
                                                    if sugg.strip():
                                                        st.markdown(f"- {sugg.strip().lstrip('-* ')}")
                                            else:
                                                st.info("AI kh√¥ng ƒë∆∞a ra g·ª£i √Ω.")
                                    else:
                                        st.info("Gemini ch∆∞a c·∫•u h√¨nh. S·ª≠ d·ª•ng g·ª£i √Ω m·∫´u:")
                                        # G·ª£i √Ω template thay th·∫ø
                                        if positive_perc >= 65:
                                            st.markdown("- Ti·∫øp t·ª•c ph√°t huy ƒëi·ªÉm m·∫°nh.\n- Lan t·ªèa ph·∫£n h·ªìi t·ªët.")
                                        elif negative_perc >= 35:
                                            st.markdown("- ∆Øu ti√™n ph√¢n t√≠ch nguy√™n nh√¢n g·ªëc r·ªÖ c·ªßa c√°c ph·∫£n h·ªìi ti√™u c·ª±c.\n- L√™n k·∫ø ho·∫°ch h√†nh ƒë·ªông kh·∫Øc ph·ª•c ngay.")
                                        else:
                                            st.markdown("- Theo d√µi s√°t sao ph·∫£n h·ªìi.\n- T√¨m c∆° h·ªôi c·∫£i thi·ªán t·ª´ nh√≥m trung t√≠nh/ti√™u c·ª±c.")

                                    st.caption(f"(D·ª±a tr√™n {total_valid} ph·∫£n h·ªìi h·ª£p l·ªá)")
                                else:
                                    st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu nh·∫≠n x√©t.")
                        else:
                            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu c·∫£m x√∫c h·ª£p l·ªá.")
                    else:
                        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu c·∫£m x√∫c.")

                    # --- N√∫t T·∫£i xu·ªëng ---
                    st.markdown("---")
                    st.subheader("üíæ T·∫£i xu·ªëng K·∫øt qu·∫£ Ph√¢n t√≠ch Nhanh")
                    @st.cache_data
                    def convert_sentiment_batch_df(df):
                        cols = ["original_comment", "sentiment", "confidence", "source", "status", "would_call_ai"]  # Th√™m c·ªôt ∆∞·ªõc t√≠nh AI
                        existing = [c for c in cols if c in df.columns]
                        try:
                            return df[existing].to_csv(index=False, encoding='utf-8-sig')
                        except:
                            return None
                    csv_sentiment_output = convert_sentiment_batch_df(results_df_batch)
                    if csv_sentiment_output:
                        st.download_button(label="üì• T·∫£i K·∫øt qu·∫£ (CSV)", data=csv_sentiment_output, file_name=f'ket_qua_sentiment_{uploaded_file_batch.name}.csv', mime='text/csv')
                    else:
                        st.error("L·ªói t·∫°o file CSV.")
                else:
                    st.warning("Kh√¥ng c√≥ d√≤ng n√†o ƒë∆∞·ª£c x·ª≠ l√Ω.")
        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω file CSV: {e}")
            traceback.print_exc()

# --- Tab 3: Th√¥ng tin Model (Gi·ªØ nguy√™n) ---
with tab3:
    st.header("Th√¥ng tin ƒê√°nh gi√° Model (XLM-RoBERTa)")
    # ... (Code hi·ªÉn th·ªã metrics, report, cm, curves, error analysis gi·ªØ nguy√™n) ...

# --- Footer ---
st.markdown("---")
st.caption("D·ª± √°n Th·ª±c t·∫≠p - X·ª≠ l√Ω Ph·∫£n h·ªìi Kh√°ch h√†ng - [T√™n c·ªßa b·∫°n]")